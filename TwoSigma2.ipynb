{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing, pipeline, metrics, model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import feature_selection\n",
    "from itertools import product\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_json('/Users/Stephanie_Zhang/Desktop/桌面/3.DS模板/代码模板/kaggle_twosigma/train.json')\n",
    "test_data = pd.read_json('/Users/Stephanie_Zhang/Desktop/桌面/3.DS模板/代码模板/kaggle_twosigma/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['target'] = train_data['interest_level'].apply(lambda x: 0 if x=='low' else 1 if x=='medium' else 2)\n",
    "train_data['low'] = train_data['interest_level'].apply(lambda x: 1 if x=='low' else 0)\n",
    "train_data['medium'] = train_data['interest_level'].apply(lambda x: 1 if x=='medium' else 0)\n",
    "train_data['high'] = train_data['interest_level'].apply(lambda x: 1 if x=='high' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data=pd.concat([train_data\n",
    "                       ,test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['bathrooms','bedrooms','latitude','longitude','price']\n",
    "cat_vars = ['building_id','manager_id','display_address','street_address']\n",
    "text_vars = ['description','features']\n",
    "date_var = 'created'\n",
    "image_var = 'photos'\n",
    "id_var = 'listing_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>high</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>low</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>medium</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>high</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features  high  \\\n",
       "10                                                     []   0.0   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...   0.0   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...   1.0   \n",
       "100007                          [Hardwood Floors, No Fee]   0.0   \n",
       "100013                                          [Pre-War]   0.0   \n",
       "\n",
       "       interest_level  latitude  listing_id  longitude  low  \\\n",
       "10             medium   40.7145     7211212   -73.9425  0.0   \n",
       "10000             low   40.7947     7150865   -73.9667  1.0   \n",
       "100004           high   40.7388     6887163   -74.0018  0.0   \n",
       "100007            low   40.7539     6888711   -73.9677  1.0   \n",
       "100013            low   40.8241     6934781   -73.9493  1.0   \n",
       "\n",
       "                              manager_id  medium  \\\n",
       "10      5ba989232d0489da1b5f2c45f6688adc     1.0   \n",
       "10000   7533621a882f71e25173b27e3139d83d     0.0   \n",
       "100004  d9039c43983f6e564b1482b273bd7b01     0.0   \n",
       "100007  1067e078446a7897d2da493d2f741316     0.0   \n",
       "100013  98e13ad4b495b9613cef886d79a6291f     0.0   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address  target  \n",
       "10      792 Metropolitan Avenue     1.0  \n",
       "10000       808 Columbus Avenue     0.0  \n",
       "100004          241 W 13 Street     2.0  \n",
       "100007     333 East 49th Street     0.0  \n",
       "100013    500 West 143rd Street     0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['created_datetime'] = pd.to_datetime(full_data['created'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data['created_year']=full_data['created_datetime'].apply(lambda x:x.year) ## low variant\n",
    "full_data['created_month']=full_data['created_datetime'].apply(lambda x:x.month)\n",
    "full_data['created_day']=full_data['created_datetime'].apply(lambda x:x.day)\n",
    "full_data['created_dayofweek']=full_data['created_datetime'].apply(lambda x:x.dayofweek)\n",
    "full_data['created_dayofyear']=full_data['created_datetime'].apply(lambda x:x.dayofyear)\n",
    "full_data['created_weekofyear']=full_data['created_datetime'].apply(lambda x:x.weekofyear)\n",
    "full_data['created_hour']=full_data['created_datetime'].apply(lambda x:x.hour)\n",
    "full_data['created_epoch']=full_data['created_datetime'].apply(lambda x:x.value//10**9)\n",
    "\n",
    "date_num_vars = ['created_month','created_dayofweek','created_dayofyear'\n",
    "                 ,'created_weekofyear','created_hour','created_epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data['price']=full_data['price'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['rooms'] = full_data['bedrooms'] + full_data['bathrooms'] \n",
    "full_data['num_of_photos'] = full_data['photos'].apply(lambda x:len(x))\n",
    "full_data['num_of_features'] = full_data['features'].apply(lambda x:len(x))\n",
    "full_data['len_of_desc'] = full_data['description'].apply(lambda x:len(x))\n",
    "full_data['words_of_desc'] = full_data['description'].apply(lambda x:len(re.sub('['+string.punctuation+']', '', x).split()))\n",
    "\n",
    "\n",
    "full_data['nums_of_desc'] = full_data['description']\\\n",
    "        .apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n",
    "        .apply(lambda x: len([s for s in x if s.isdigit()]))\n",
    "        \n",
    "full_data['has_phone'] = full_data['description'].apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n",
    "        .apply(lambda x: [s for s in x if s.isdigit()])\\\n",
    "        .apply(lambda x: len([s for s in x if len(str(s))==10]))\\\n",
    "        .apply(lambda x: 1 if x>0 else 0)\n",
    "full_data['has_email'] = full_data['description'].apply(lambda x: 1 if '@renthop.com' in x else 0)\n",
    "\n",
    "additional_num_vars = ['rooms','num_of_photos','num_of_features','len_of_desc',\n",
    "                    'words_of_desc','has_phone','has_email']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['avg_word_len'] = full_data[['len_of_desc','words_of_desc']]\\\n",
    "                                    .apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "    \n",
    "full_data['price_per_room'] = full_data[['price','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_bedroom'] = full_data[['price','bedrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_bathroom'] = full_data[['price','bathrooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "full_data['price_per_photo'] = full_data[['price','num_of_photos']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "\n",
    "full_data['photos_per_room'] = full_data[['num_of_photos','rooms']].apply(lambda x: x[0]/x[1] if x[1]!=0 else 0, axis=1)\n",
    "\n",
    "interactive_num_vars = ['avg_word_len','price_per_room','price_per_bedroom','price_per_bathroom','price_per_photo',\n",
    "                        'photos_per_room']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding building_id\n",
      "Label Encoding manager_id\n",
      "Label Encoding display_address\n",
      "Label Encoding street_address\n",
      "Label-encoded feaures: ['building_id_le', 'manager_id_le', 'display_address_le', 'street_address_le']\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "\n",
    "LE_vars=[]\n",
    "LE_map=dict()\n",
    "for cat_var in cat_vars:\n",
    "    print (\"Label Encoding %s\" % (cat_var))\n",
    "    LE_var=cat_var+'_le'\n",
    "    full_data[LE_var]=LBL.fit_transform(full_data[cat_var])\n",
    "    LE_vars.append(LE_var)\n",
    "    LE_map[cat_var]=LBL.classes_\n",
    "    \n",
    "print (\"Label-encoded feaures: %s\" % (LE_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-encoding finished in 0.218343 seconds\n",
      "OHE_sparse size : (124011, 57868)\n",
      "One-hot encoded catgorical feature samples : ['building_0', 'building_00005cb939f9986300d987652c933e15', 'building_00024d77a43f0606f926e2312513845c', 'building_000ae4b7db298401cdae2b0ba1ea8146', 'building_0012f1955391bca600ec301035b97b65', 'building_0021440c04241281a436ec21accc40b1', 'building_002d1eba40aa0a6610e04ff20543585f', 'building_003d8740e21484dcc2280639b25539a4', 'building_00480e54b53fe77d17964be3f8307a99', 'building_00553d95d22484bcc36831c9248d1dbc', 'building_0055c8662ba19e95f78df97592d2b83e', 'building_0056dbdf2881b76f2a0171eb753ec9e0', 'building_0059ae562b9e338a59eaf962cb3eedd2', 'building_005e0f8d7fb7b92be351cbf1dd985149', 'building_0067f166111490e7af7f1a878a67bb5e', 'building_0070bc94a3f80aa717bb15708e98ba54', 'building_0071cda335745940cdae1dc31abfc701', 'building_0078281cd69f4bfec17e42e5cf5eecd9', 'building_0078c2ab46afba9969637ac83621901e', 'building_007ae1cd90420f18bad7b6892a9a1411', 'building_007cd8edc45c6cfbcabd88f70d59a513', 'building_008d3e3a11295305966844713b685f7d', 'building_008ff72d77a8fc85eccfc4ec33ec09a3', 'building_0095cb49c423ec7b204e26d76c56bd35', 'building_009c6ad006e8fd679991c5f8cffaef9f', 'building_009f494b0636f32b96b41926ec7c4bf2', 'building_00a4e18de6c9a7bbec33c77e0588a3b9', 'building_00a61b88186b5115356374b0f5dd0d1e', 'building_00a7b4a6aec7ca1a1635c622918b68f0', 'building_00a94a38fcda000b4448370839a25ac8', 'building_00b2da856a75f0f5690996b0a0b1f397', 'building_00bafd8e05682a7c7e36b4046acd0f1b', 'building_00bb734cde488aa3e1f3e5f1376b9c13', 'building_00cca782a37fc2bb91b080ede56fa7cf', 'building_00ce59a4de554163bda36549de6bf967', 'building_00d1b109f921cd8bc69a203bf35a9bac', 'building_00dfd2bccb9127f2e7966ff29ae1e060', 'building_00e3e6bb0d19bb601842c0ab9589f9a2', 'building_00e8bbc4c74980a06c187165d9a5869e', 'building_00e980b7c97376eb19e0b1be650ccb64', 'building_00ecc203c49a4651cf186de65f308ac1', 'building_00fdda7f129d05ab200c31c0c6de8dfd', 'building_00ffdfd150acc0b097182bbf9dd1db28', 'building_0103d0d57f197a73cdfd0f2f26870d74', 'building_010435ab3b0b415421d583937a55283e', 'building_0106f282d2dfe616303b86e5b68df6b4', 'building_010f3d0141cd76667ca8e3d86e221cf2', 'building_0114c80bf2a9027612083e354d7fbdbc', 'building_0117976b081298aea99e21c327ab25a4', 'building_011a3c781df937c2991a3832b547b158', 'building_01298c8fd1e6e332fb4c188a7183a206', 'building_012fcf2833e0e07897b682ab6f82be3b', 'building_013a96b772f0e46731faee50ad25d727', 'building_01401bc9a8908b2d6ffa84ebf9e1b984', 'building_0145e758b990b8d2648ee57c30762d76', 'building_0152c6255a4e29051b817ce6f3f6dd6f', 'building_0155fa9629c4d68dbe9106b9ac3866ad', 'building_015901f6966b695aec0bda32e36423d6', 'building_015bf4a41140bb7304d338437192f2ab', 'building_015cf622b143eb8703307cf591e9dd46', 'building_01601e509316d5e48176d0f034e04f9f', 'building_016124e48651db465762bfbaf7a9080b', 'building_0162edae269da1472fcbdf4f61df7c7a', 'building_0165775b1775642fb0f71595e83484ba', 'building_0166aa8add8bdc29ca360ab1db5c77f9', 'building_016e30568187a4bd83bf86ca02837544', 'building_017c4715165fe36e5a4372ebf15207f1', 'building_017c9eb62166b050a144adad22b91c00', 'building_017e4ac152c10d537fb2acb3743f2162', 'building_018023115a3d3d3273b25a3357e5358a', 'building_0180389cfd65c7037149466dc934afd3', 'building_01813414c43aedaf8f1b1fb74cef3f99', 'building_018b0a85428622d9a6447fd475cf8bff', 'building_018cd3169a68bd83a92c341d8349b77d', 'building_01904e878eec9c80a40d70f6495454c2', 'building_0195041256b2514a6047a340b0561c3e', 'building_019adbb79eb99ed4c4b9dea91571aa91', 'building_019ce6c2904c70141b3c6fd6d7557344', 'building_019e909a65d7d2e3bf22c6334bf15a7e', 'building_01a430b383a468bcfb6a6dec9f6d42cd', 'building_01a8c78a8ec0234b5e9bd8645fb2ce43', 'building_01acba2c701ccf3528ddf17f1006f694', 'building_01ae28a1834d9bb940cfa2daa78b59c6', 'building_01bb059f7b7619ed7a5f74a97b9ce2ed', 'building_01bd855b1c9b786e37c13c25e5a81fda', 'building_01bfd6631a820706cb16bae93585d998', 'building_01cb79b2d06a9844231c42b3f05eb0c2', 'building_01cb7ce5bc25ca98fcca6ed5236c3224', 'building_01cd1cd0b21bbd22da7381a248d4fdc8', 'building_01cefee671bc17927058c0c579d459cb', 'building_01d767115586534b39d5224710dc56a4', 'building_01d79491cfd8271eaf73a5d69a759ef0', 'building_01d7a001b3a497c25c3a01955d45c339', 'building_01db3503f72909222100231ff6905a78', 'building_01df496b33f2402c5c18076b5f45c916', 'building_01e23bdc82cbdb20a15d290c02572a5d', 'building_01ee5fb703946538f9a34e22f48939e9', 'building_01f27b3de1bf1ee3218e88e64c3315a0', 'building_01f582fe206ca52144a3ac43c14653f7', 'building_01f85713461b5be6a172f4c3db190668']\n"
     ]
    }
   ],
   "source": [
    "OHE = preprocessing.OneHotEncoder(sparse=True)\n",
    "start=time.time()\n",
    "OHE.fit(full_data[LE_vars])\n",
    "OHE_sparse=OHE.transform(full_data[LE_vars])\n",
    "                                   \n",
    "print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "\n",
    "OHE_vars = [var[:-3] + '_' + str(level).replace(' ','_')\\\n",
    "                for var in cat_vars for level in LE_map[var] ]\n",
    "\n",
    "print (\"OHE_sparse size :\" ,OHE_sparse.shape)\n",
    "print (\"One-hot encoded catgorical feature samples : %s\" % (OHE_vars[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Leave-one-out Encoding\n",
    "\n",
    "Based on the paper \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems\"\n",
    "\n",
    "http://helios.mm.di.uoa.gr/~rouvas/ssi/sigkdd/sigkdd.vol3.1/barreca.ps\n",
    "\n",
    "** A couple of Kaggle scripts: **\n",
    "\n",
    "R version: by Braden Murray: https://www.kaggle.com/brandenkmurray/two-sigma-connect-rental-listing-inquiries/it-is-lit/comments\n",
    "\n",
    "Python Version 1, by Stanislav Ushakov\n",
    "https://www.kaggle.com/stanislavushakov/two-sigma-connect-rental-listing-inquiries/python-version-of-it-is-lit-by-branden/comments\n",
    "\n",
    "Python Version 2, by Rakhlin\n",
    "https://www.kaggle.com/rakhlin/two-sigma-connect-rental-listing-inquiries/another-python-version-of-it-is-lit-by-branden/code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designate_single_observations(df1, df2, column):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = train_data['building_id'].append(test_data['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10        53a5b119ba8f7b61d4e010512e0dfc85\n",
       "10000     c5c8a357cba207596b04d1afd1e4f130\n",
       "100004    c3ba40552e2120b0acfc3cb5730bb2aa\n",
       "100007    28d9ad350afeaab8027513a3e52ac8d5\n",
       "100013                                   0\n",
       "100014    38a913e46c94a7f46ddf19b756a9640c\n",
       "100016    3ba49a93260ca5df92fde024cb4ca61f\n",
       "100020    0372927bcb6a0949613ef5bf893bbac7\n",
       "100026    a7efbeb58190aa267b4a9121cd0c88c0\n",
       "100027                                   0\n",
       "100030                                   0\n",
       "10004                                    0\n",
       "100044    67c9b420da4a365bc26a6cd0ef4a5320\n",
       "100048                                   0\n",
       "10005                                    0\n",
       "100051    bfb9405149bfff42a92980b594c28234\n",
       "100052    642cc2c920512ffe2a74c28122f8b47f\n",
       "100053                                   0\n",
       "100055    cc4c6ae9225df6d2395c4e16c235f7ab\n",
       "100058    dc3cae15729b48fec3394f9295671991\n",
       "Name: building_id, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00005cb939f9986300d987652c933e15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00024d77a43f0606f926e2312513845c</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000ae4b7db298401cdae2b0ba1ea8146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012f1955391bca600ec301035b97b65</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0021440c04241281a436ec21accc40b1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d1eba40aa0a6610e04ff20543585f</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003d8740e21484dcc2280639b25539a4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00480e54b53fe77d17964be3f8307a99</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00553d95d22484bcc36831c9248d1dbc</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0055c8662ba19e95f78df97592d2b83e</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0056dbdf2881b76f2a0171eb753ec9e0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0059ae562b9e338a59eaf962cb3eedd2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005e0f8d7fb7b92be351cbf1dd985149</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0067f166111490e7af7f1a878a67bb5e</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0070bc94a3f80aa717bb15708e98ba54</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0071cda335745940cdae1dc31abfc701</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0078281cd69f4bfec17e42e5cf5eecd9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0078c2ab46afba9969637ac83621901e</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007ae1cd90420f18bad7b6892a9a1411</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  building_id\n",
       "building_id                                  \n",
       "0                                       20664\n",
       "00005cb939f9986300d987652c933e15            1\n",
       "00024d77a43f0606f926e2312513845c            7\n",
       "000ae4b7db298401cdae2b0ba1ea8146            2\n",
       "0012f1955391bca600ec301035b97b65            1\n",
       "0021440c04241281a436ec21accc40b1           20\n",
       "002d1eba40aa0a6610e04ff20543585f            2\n",
       "003d8740e21484dcc2280639b25539a4            1\n",
       "00480e54b53fe77d17964be3f8307a99            3\n",
       "00553d95d22484bcc36831c9248d1dbc           11\n",
       "0055c8662ba19e95f78df97592d2b83e            1\n",
       "0056dbdf2881b76f2a0171eb753ec9e0            1\n",
       "0059ae562b9e338a59eaf962cb3eedd2            1\n",
       "005e0f8d7fb7b92be351cbf1dd985149            1\n",
       "0067f166111490e7af7f1a878a67bb5e            6\n",
       "0070bc94a3f80aa717bb15708e98ba54            1\n",
       "0071cda335745940cdae1dc31abfc701           12\n",
       "0078281cd69f4bfec17e42e5cf5eecd9            1\n",
       "0078c2ab46afba9969637ac83621901e            5\n",
       "007ae1cd90420f18bad7b6892a9a1411            1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a function to encode high-cardinality cateogrical features\n",
    "\n",
    "def designate_single_observations(df1, df2, column):\n",
    "    ps = df1[column].append(df2[column])\n",
    "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
    "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
    "    return df1, df2\n",
    "\n",
    "\n",
    "def hcc_encode(train_df, test_df, variable, target, prior_prob, k, f=1, g=1, r_k=None, update_df=None):\n",
    "    \"\"\"\n",
    "    See \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in\n",
    "    Classification and Prediction Problems\" by Daniele Micci-Barreca\n",
    "    \"\"\"\n",
    "    hcc_name = \"_\".join([\"hcc\", variable, target])\n",
    "\n",
    "    grouped = train_df.groupby(variable)[target].agg({\"size\": \"size\", \"mean\": \"mean\"})\n",
    "    grouped[\"lambda\"] = 1 / (g + np.exp((k - grouped[\"size\"]) / f))\n",
    "    grouped[hcc_name] = grouped[\"lambda\"] * grouped[\"mean\"] + (1 - grouped[\"lambda\"]) * prior_prob\n",
    "\n",
    "    df = test_df[[variable]].join(grouped, on=variable, how=\"left\")[hcc_name].fillna(prior_prob)\n",
    "    if r_k: df *= np.random.uniform(1 - r_k, 1 + r_k, len(test_df))     # Add uniform noise. Not mentioned in original paper\n",
    "\n",
    "    if update_df is None: update_df = test_df\n",
    "    if hcc_name not in update_df.columns: update_df[hcc_name] = np.nan\n",
    "    update_df.update(df)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    }
   ],
   "source": [
    "# for col in ('building_id', 'manager_id', 'display_address'):\n",
    "#     train_data, test_data = designate_single_observations(train_data, test_data, col)\n",
    "    \n",
    "prior_low, prior_medium, prior_high = train_data[[\"low\", \"medium\", \"high\"]].mean() \n",
    "\n",
    "skf = model_selection.StratifiedKFold(5)\n",
    "attributes = product((\"building_id\", \"manager_id\"), zip((\"medium\", \"high\"), (prior_medium, prior_high)))\n",
    "for variable, (target, prior) in attributes:\n",
    "    hcc_encode(train_data, test_data, variable, target, prior, k=5, r_k=None)\n",
    "    for train, test in skf.split(np.zeros(len(train_data)), train_data['interest_level']):\n",
    "        hcc_encode(train_data.iloc[train], train_data.iloc[test], variable, target, prior, k=5, r_k=0.01,\n",
    "                   update_df=train_data)\n",
    "        \n",
    "hcc_data = pd.concat([train_data[['building_id', 'manager_id', 'display_address',\n",
    "            'hcc_building_id_medium','hcc_building_id_high',\n",
    "            'hcc_manager_id_medium','hcc_manager_id_high']],\n",
    "           test_data[['building_id', 'manager_id', 'display_address',\n",
    "            'hcc_building_id_medium','hcc_building_id_high',\n",
    "            'hcc_manager_id_medium','hcc_manager_id_high']]\n",
    "           ]\n",
    "          )\n",
    "full_data['building_id'] = hcc_data['building_id']\n",
    "full_data['manager_id'] = hcc_data['manager_id']\n",
    "full_data['display_address'] = hcc_data['display_address']\n",
    "full_data['hcc_building_id_medium'] = hcc_data['hcc_building_id_medium']\n",
    "full_data['hcc_building_id_high'] = hcc_data['hcc_building_id_high']\n",
    "full_data['hcc_manager_id_medium'] = hcc_data['hcc_manager_id_medium']\n",
    "full_data['hcc_manager_id_high'] = hcc_data['hcc_manager_id_high']\n",
    "hcc_vars = ['hcc_building_id_medium','hcc_building_id_high','hcc_manager_id_medium','hcc_manager_id_high']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
    "cntvec = CountVectorizer(stop_words='english', max_features=200)\n",
    "feature_sparse =cntvec.fit_transform(full_data[\"features\"]\\\n",
    "                                     .apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x])))\n",
    "\n",
    "feature_vars = ['feature_' + v for v in cntvec.vocabulary_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tf-idf not working, instead, using CountVectorizer, not working either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "# desc_sparse = tfidf.fit_transform(full_data[\"description\"])\n",
    "# desc_vars = ['desc_' + v for v in tfidf.get_feature_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntvec = CountVectorizer(stop_words='english', max_features=100)\n",
    "desc_sparse = cntvec.fit_transform(full_data[\"description\"])\n",
    "desc_vars = ['desc_' + v for v in cntvec.vocabulary_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### word2vec - to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntvec = CountVectorizer(stop_words='english', max_features=10)\n",
    "st_addr_sparse = cntvec.fit_transform(full_data[\"street_address\"])\n",
    "st_addr_vars = ['desc_' + v for v in cntvec.vocabulary_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image vars - to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numberic vs Categorical Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_by_manager = full_data.groupby('manager_id')['price'].agg([np.min,np.max,np.median,np.mean]).reset_index()\n",
    "price_by_manager.columns = ['manager_id','min_price_by_manager',\n",
    "                            'max_price_by_manager','median_price_by_manager','mean_price_by_manager']\n",
    "full_data = pd.merge(full_data,price_by_manager, how='left',on='manager_id')\n",
    "\n",
    "price_by_building = full_data.groupby('building_id')['price'].agg([np.min,np.max,np.median,np.mean]).reset_index()\n",
    "price_by_building.columns = ['building_id','min_price_by_building',\n",
    "                            'max_price_by_building','median_price_by_building','mean_price_by_building']\n",
    "full_data = pd.merge(full_data,price_by_building, how='left',on='building_id')\n",
    "\n",
    "price_by_disp_addr = full_data.groupby('display_address')['price'].agg([np.min,np.max,np.median,np.mean]).reset_index()\n",
    "price_by_disp_addr.columns = ['display_address','min_price_by_disp_addr',\n",
    "                            'max_price_by_disp_addr','median_price_by_disp_addr','mean_price_by_disp_addr']\n",
    "full_data = pd.merge(full_data,price_by_disp_addr, how='left',on='display_address')\n",
    "\n",
    "num_cat_vars = ['median_price_by_manager','mean_price_by_manager',\n",
    "                'median_price_by_building','mean_price_by_building',\n",
    "                'median_price_by_disp_addr','mean_price_by_disp_addr'\n",
    "               ]\n",
    "\n",
    "full_data['price_percentile_by_manager']=\\\n",
    "            full_data[['price','min_price_by_manager','max_price_by_manager']]\\\n",
    "            .apply(lambda x:(x[0]-x[1])/(x[2]-x[1]) if (x[2]-x[1])!=0 else 0.5,\n",
    "                  axis=1)\n",
    "full_data['price_percentile_by_building']=\\\n",
    "            full_data[['price','min_price_by_building','max_price_by_building']]\\\n",
    "            .apply(lambda x:(x[0]-x[1])/(x[2]-x[1]) if (x[2]-x[1])!=0 else 0.5,\n",
    "                  axis=1)\n",
    "full_data['price_percentile_by_disp_addr']=\\\n",
    "            full_data[['price','min_price_by_disp_addr','max_price_by_disp_addr']]\\\n",
    "            .apply(lambda x:(x[0]-x[1])/(x[2]-x[1]) if (x[2]-x[1])!=0 else 0.5,\n",
    "                  axis=1)\n",
    "\n",
    "num_cat_vars.append('price_percentile_by_manager')\n",
    "num_cat_vars.append('price_percentile_by_building')\n",
    "num_cat_vars.append('price_percentile_by_disp_addr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing ID matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_listing_id = full_data['listing_id'].min()\n",
    "max_listing_id = full_data['listing_id'].max()\n",
    "full_data['listing_id_pos']=full_data['listing_id'].apply(lambda x:np.float64((x-min_listing_id+1))/(max_listing_id-min_listing_id+1))\n",
    "num_vars.append('listing_id')\n",
    "num_vars.append('listing_id_pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size:  (49352, 253) testing data size:  (74659, 253)\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[263]\ttrain-mlogloss:0.336701+0.0015079\ttest-mlogloss:0.533393+0.00585737\n",
      "\n",
      "CPU times: user 19min 51s, sys: 16.6 s, total: 20min 7s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##Baseline with features from \"features\" and street address\n",
    "\n",
    "full_vars = num_vars + date_num_vars + additional_num_vars + interactive_num_vars + LE_vars + hcc_vars + num_cat_vars\n",
    "\n",
    "train_x = sparse.hstack([full_data[full_vars], feature_sparse,st_addr_sparse]).tocsr()[:train_size]\n",
    "train_y = full_data['target'][:train_size].values\n",
    "\n",
    "test_x = sparse.hstack([full_data[full_vars], feature_sparse,st_addr_sparse]).tocsr()[train_size:]\n",
    "test_y = full_data['target'][train_size:].values\n",
    "\n",
    "\n",
    "full_vars = full_vars + feature_vars + st_addr_vars\n",
    "print (\"training data size: \", train_x.shape,\"testing data size: \", test_x.shape)\n",
    "\n",
    "\n",
    "params = dict()\n",
    "params['objective'] = 'multi:softprob'\n",
    "params['num_class'] = 3\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 6\n",
    "params['min_child_weight'] = 1\n",
    "params['subsample'] = 0.7\n",
    "params['colsample_bytree'] = 0.7\n",
    "params['gamma'] = 1\n",
    "params['seed']=1234\n",
    "\n",
    "cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "               num_boost_round=1000000, nfold=5,\n",
    "       metrics={'mlogloss'},\n",
    "       seed=1234,\n",
    "       callbacks=[xgb.callback.early_stop(50)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuanl Tuning\n",
    "\n",
    "* Greedy-search\n",
    "* Tune one parameter a time\n",
    "* The results can be used for further tuning (by Bayesian Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[958]\ttrain-mlogloss:0.429892+0.000876112\ttest-mlogloss:0.536051+0.0064062\n",
      "\n",
      "3 0.5360507999999999 959\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[635]\ttrain-mlogloss:0.393214+0.000905466\ttest-mlogloss:0.534002+0.00639002\n",
      "\n",
      "4 0.5340022 636\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[380]\ttrain-mlogloss:0.377163+0.00245438\ttest-mlogloss:0.534756+0.00590177\n",
      "\n",
      "5 0.534756 381\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[266]\ttrain-mlogloss:0.349947+0.00320998\ttest-mlogloss:0.534694+0.0052274\n",
      "\n",
      "6 0.5346944 267\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[198]\ttrain-mlogloss:0.319904+0.00243284\ttest-mlogloss:0.535869+0.00692058\n",
      "\n",
      "7 0.5358686 199\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[140]\ttrain-mlogloss:0.302272+0.00232999\ttest-mlogloss:0.537094+0.00641439\n",
      "\n",
      "8 0.5370938000000001 141\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[111]\ttrain-mlogloss:0.269852+0.00184806\ttest-mlogloss:0.53954+0.00704187\n",
      "\n",
      "9 0.5395398 112\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[81]\ttrain-mlogloss:0.254206+0.00162486\ttest-mlogloss:0.544306+0.00636548\n",
      "\n",
      "10 0.5443064000000001 82\n",
      "best max_depth is 4\n",
      "CPU times: user 3h 44min 55s, sys: 2min 53s, total: 3h 47min 48s\n",
      "Wall time: 1h 31min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_scores = pd.DataFrame()\n",
    "scores = []\n",
    "for max_depth in [3,4,5,6,7,8,9,10]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = 1\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['gamma'] = 0\n",
    "    params['seed']=1234\n",
    "\n",
    "    cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "                   num_boost_round=1000000,\n",
    "                   nfold=5,\n",
    "           metrics={'mlogloss'},\n",
    "           seed=1234,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    best_iteration = len(cv_results)\n",
    "    best_score = cv_results['test-mlogloss-mean'].min()\n",
    "    print (max_depth,best_score,best_iteration)\n",
    "    scores.append([best_score,params['eta'],params['max_depth'],params['min_child_weight'],\n",
    "                      params['colsample_bytree'],params['subsample'],params['gamma'],best_iteration])\n",
    "xgb_scores = pd.concat([xgb_scores, pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration'])])    \n",
    "best_max_depth = int(pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration']).\\\n",
    "                     sort_values(by='score',ascending=True)['max_depth'].values[0])\n",
    "print ('best max_depth is', best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[635]\ttrain-mlogloss:0.393214+0.000905466\ttest-mlogloss:0.534002+0.00639002\n",
      "\n",
      "1 0.5340022 636\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[643]\ttrain-mlogloss:0.393131+0.00151903\ttest-mlogloss:0.534294+0.00676678\n",
      "\n",
      "3 0.5342935999999999 644\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[591]\ttrain-mlogloss:0.403538+0.00180947\ttest-mlogloss:0.534165+0.00532355\n",
      "\n",
      "10 0.5341646 592\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[573]\ttrain-mlogloss:0.415993+0.00192655\ttest-mlogloss:0.533871+0.00539452\n",
      "\n",
      "30 0.5338708000000001 574\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[706]\ttrain-mlogloss:0.427133+0.00074828\ttest-mlogloss:0.534508+0.00580978\n",
      "\n",
      "100 0.5345078 707\n",
      "best min_child_weight is 30\n",
      "CPU times: user 3h 2min 50s, sys: 1min 58s, total: 3h 4min 49s\n",
      "Wall time: 57min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for min_child_weight in [1,3,10,30,100]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = best_max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = 1\n",
    "    params['gamma'] = 0\n",
    "    params['seed']=1234\n",
    "\n",
    "    cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "                   num_boost_round=1000000,\n",
    "                   nfold=5,\n",
    "           metrics={'mlogloss'},\n",
    "           seed=1234,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    best_iteration = len(cv_results)\n",
    "    best_score = cv_results['test-mlogloss-mean'].min()\n",
    "    print (min_child_weight,best_score,best_iteration)\n",
    "    scores.append([best_score,params['eta'],params['max_depth'],params['min_child_weight'],\n",
    "                      params['colsample_bytree'],params['subsample'],params['gamma'],best_iteration])\n",
    "xgb_scores = pd.concat([xgb_scores, pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration'])])    \n",
    "best_min_child_weight = int(pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration']).sort_values(by='score',ascending=True)['min_child_weight'].values[0])\n",
    "print ('best min_child_weight is', best_min_child_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[743]\ttrain-mlogloss:0.414957+0.00172298\ttest-mlogloss:0.533292+0.00587709\n",
      "\n",
      "0.2 0.5332918 744\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[716]\ttrain-mlogloss:0.409833+0.00249919\ttest-mlogloss:0.53343+0.00661121\n",
      "\n",
      "0.3 0.5334296000000001 717\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[627]\ttrain-mlogloss:0.416875+0.00243065\ttest-mlogloss:0.53284+0.00596032\n",
      "\n",
      "0.4 0.5328396 628\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[792]\ttrain-mlogloss:0.392532+0.00226816\ttest-mlogloss:0.532213+0.0061497\n",
      "\n",
      "0.5 0.5322128 793\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[600]\ttrain-mlogloss:0.416219+0.0024475\ttest-mlogloss:0.532739+0.00580829\n",
      "\n",
      "0.6 0.5327392000000001 601\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[657]\ttrain-mlogloss:0.406466+0.0016381\ttest-mlogloss:0.532841+0.00524034\n",
      "\n",
      "0.7 0.5328412 658\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[602]\ttrain-mlogloss:0.413496+0.00225592\ttest-mlogloss:0.533379+0.00514403\n",
      "\n",
      "0.8 0.5333786 603\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[647]\ttrain-mlogloss:0.40492+0.0022681\ttest-mlogloss:0.533803+0.00530978\n",
      "\n",
      "0.9 0.5338032 648\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[573]\ttrain-mlogloss:0.415993+0.00192655\ttest-mlogloss:0.533871+0.00539452\n",
      "\n",
      "1 0.5338708000000001 574\n",
      "best colsample_bytree is 0.5\n",
      "CPU times: user 4h 22min 6s, sys: 3min 15s, total: 4h 25min 21s\n",
      "Wall time: 2h 19min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for colsample_bytree in [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = best_max_depth\n",
    "    params['min_child_weight'] = best_min_child_weight\n",
    "    params['subsample'] = 1\n",
    "    params['colsample_bytree'] = colsample_bytree\n",
    "    params['gamma'] = 0\n",
    "    params['seed']=1234\n",
    "\n",
    "    cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "                   num_boost_round=1000000,\n",
    "                   nfold=5,\n",
    "           metrics={'mlogloss'},\n",
    "           seed=1234,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    best_iteration = len(cv_results)\n",
    "    best_score = cv_results['test-mlogloss-mean'].min()\n",
    "    print (colsample_bytree,best_score,best_iteration)\n",
    "    scores.append([best_score,params['eta'],params['max_depth'],params['min_child_weight'],\n",
    "                      params['colsample_bytree'],params['subsample'],params['gamma'],best_iteration])\n",
    "xgb_scores = pd.concat([xgb_scores, pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration'])])    \n",
    "best_colsample_bytree = pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration']).sort_values(by='score',ascending=True)['colsample_bytree'].values[0]\n",
    "\n",
    "\n",
    "print ('best colsample_bytree is', best_colsample_bytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[622]\ttrain-mlogloss:0.416074+0.001868\ttest-mlogloss:0.534226+0.005924\n",
      "\n",
      "0.6 0.5342256 623\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[572]\ttrain-mlogloss:0.4217+0.001403\ttest-mlogloss:0.533259+0.00626368\n",
      "\n",
      "0.7 0.5332586 573\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[686]\ttrain-mlogloss:0.403628+0.00206652\ttest-mlogloss:0.53219+0.00608093\n",
      "\n",
      "0.8 0.5321904000000001 687\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[728]\ttrain-mlogloss:0.398287+0.00123031\ttest-mlogloss:0.532256+0.00560962\n",
      "\n",
      "0.9 0.5322560000000001 729\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[792]\ttrain-mlogloss:0.392532+0.00226816\ttest-mlogloss:0.532213+0.0061497\n",
      "\n",
      "1 0.5322128 793\n",
      "best subsample is 0.8\n",
      "CPU times: user 2h 48min 19s, sys: 2min 22s, total: 2h 50min 42s\n",
      "Wall time: 51min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for subsample in [0.6,0.7,0.8,0.9,1]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = best_max_depth\n",
    "    params['min_child_weight'] = best_min_child_weight\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = best_colsample_bytree\n",
    "    params['gamma'] = 0\n",
    "    params['seed']=1234\n",
    "\n",
    "    cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "                   num_boost_round=1000000,\n",
    "                   nfold=5,\n",
    "           metrics={'mlogloss'},\n",
    "           seed=1234,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    best_iteration = len(cv_results)\n",
    "    best_score = cv_results['test-mlogloss-mean'].min()\n",
    "    print (subsample,best_score,best_iteration)\n",
    "    scores.append([best_score,params['eta'],params['max_depth'],params['min_child_weight'],\n",
    "                      params['colsample_bytree'],params['subsample'],params['gamma'],best_iteration])\n",
    "xgb_scores = pd.concat([xgb_scores, pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration'])])    \n",
    "best_subsample = pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration']).sort_values(by='score',ascending=True)['subsample'].values[0]\n",
    "\n",
    "print ('best subsample is', best_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[686]\ttrain-mlogloss:0.403628+0.00206652\ttest-mlogloss:0.53219+0.00608093\n",
      "\n",
      "0 0.5321904000000001 687\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[652]\ttrain-mlogloss:0.408647+0.00169269\ttest-mlogloss:0.532065+0.00561747\n",
      "\n",
      "0.5 0.5320654 653\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[736]\ttrain-mlogloss:0.397305+0.00146662\ttest-mlogloss:0.532279+0.00555404\n",
      "\n",
      "1 0.5322785999999999 737\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[706]\ttrain-mlogloss:0.403395+0.00170993\ttest-mlogloss:0.531775+0.00551301\n",
      "\n",
      "1.5 0.531775 707\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[740]\ttrain-mlogloss:0.404901+0.00163425\ttest-mlogloss:0.531764+0.00525731\n",
      "\n",
      "2 0.5317642 741\n",
      "best gamma is 2.0\n",
      "CPU times: user 2h 51min 3s, sys: 2min 23s, total: 2h 53min 27s\n",
      "Wall time: 52min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for gamma in [0,0.5,1,1.5,2]:\n",
    "\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = best_max_depth\n",
    "    params['min_child_weight'] = best_min_child_weight\n",
    "    params['subsample'] = best_subsample\n",
    "    params['colsample_bytree'] = best_colsample_bytree\n",
    "    params['gamma'] = gamma\n",
    "    params['seed']=1234\n",
    "\n",
    "    cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "                   num_boost_round=1000000,\n",
    "                   nfold=5,\n",
    "           metrics={'mlogloss'},\n",
    "           seed=1234,\n",
    "           callbacks=[xgb.callback.early_stop(50)])\n",
    "    best_iteration = len(cv_results)\n",
    "    best_score = cv_results['test-mlogloss-mean'].min()\n",
    "    print (gamma,best_score,best_iteration)\n",
    "    scores.append([best_score,params['eta'],params['max_depth'],params['min_child_weight'],\n",
    "                      params['colsample_bytree'],params['subsample'],params['gamma'],best_iteration])\n",
    "xgb_scores = pd.concat([xgb_scores, pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration'])])    \n",
    "best_gamma = pd.DataFrame(scores,columns=['score','eta','max_depth','min_child_weight',\n",
    "                                   'colsample_bytree','subsample','gamma','best_iteration']).sort_values(by='score',ascending=True)['gamma'].values[0]\n",
    "\n",
    "print ('best gamma is', best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Tuning\n",
    "\n",
    "* https://github.com/fmfn/BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[664]\ttrain-mlogloss:0.421339+0.000681717\ttest-mlogloss:0.532639+0.00573918\n",
      "\n",
      "    1 | 09m08s | \u001b[35m  -0.53264\u001b[0m | \u001b[32m            0.4514\u001b[0m | \u001b[32m   1.3906\u001b[0m | \u001b[32m     4.7931\u001b[0m | \u001b[32m           51.7031\u001b[0m | \u001b[32m     0.8260\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[331]\ttrain-mlogloss:0.379085+0.000902274\ttest-mlogloss:0.53208+0.00475385\n",
      "\n",
      "    2 | 07m19s | \u001b[35m  -0.53208\u001b[0m | \u001b[32m            0.4619\u001b[0m | \u001b[32m   0.2945\u001b[0m | \u001b[32m     6.5639\u001b[0m | \u001b[32m           29.6693\u001b[0m | \u001b[32m     0.7304\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[328]\ttrain-mlogloss:0.378303+0.000804082\ttest-mlogloss:0.531648+0.00549069\n",
      "\n",
      "    3 | 10m50s | \u001b[35m  -0.53165\u001b[0m | \u001b[32m            0.6320\u001b[0m | \u001b[32m   0.2041\u001b[0m | \u001b[32m     7.3314\u001b[0m | \u001b[32m           70.8628\u001b[0m | \u001b[32m     0.8344\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[581]\ttrain-mlogloss:0.411531+0.00152984\ttest-mlogloss:0.532939+0.00581184\n",
      "\n",
      "    4 | 08m35s |   -0.53294 |             0.3844 |    0.7108 |      5.8947 |            95.6816 |      0.8631 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[487]\ttrain-mlogloss:0.389259+0.00161636\ttest-mlogloss:0.531416+0.00580973\n",
      "\n",
      "    5 | 06m37s | \u001b[35m  -0.53142\u001b[0m | \u001b[32m            0.2258\u001b[0m | \u001b[32m   1.8056\u001b[0m | \u001b[32m     7.2895\u001b[0m | \u001b[32m           82.5169\u001b[0m | \u001b[32m     0.9829\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[243]\ttrain-mlogloss:0.35613+0.00131962\ttest-mlogloss:0.531627+0.00562743\n",
      "\n",
      "    6 | 09m33s |   -0.53163 |             0.6821 |    1.9926 |      7.9487 |            17.7515 |      0.7957 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([5.60553949e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 46, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[455]\ttrain-mlogloss:0.385036+0.000847493\ttest-mlogloss:0.533828+0.00565615\n",
      "\n",
      "    7 | 06m28s |   -0.53383 |             0.2253 |    1.8849 |      7.9444 |            61.1723 |      0.7245 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[732]\ttrain-mlogloss:0.380285+0.00116659\ttest-mlogloss:0.534154+0.00570804\n",
      "\n",
      "    8 | 06m42s |   -0.53415 |             0.2481 |    0.0315 |      4.1202 |             0.0117 |      0.7285 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00025656]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[771]\ttrain-mlogloss:0.420303+0.00179888\ttest-mlogloss:0.534284+0.00581202\n",
      "\n",
      "    9 | 14m15s |   -0.53428 |             0.6651 |    1.9934 |      4.1291 |            83.3612 |      0.7008 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.92302759e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[751]\ttrain-mlogloss:0.395428+0.00167569\ttest-mlogloss:0.531833+0.00587994\n",
      "\n",
      "   10 | 14m37s |   -0.53183 |             0.6875 |    1.9625 |      4.1302 |            18.6184 |      0.9508 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[850]\ttrain-mlogloss:0.423143+0.000620016\ttest-mlogloss:0.53361+0.00591265\n",
      "\n",
      "   11 | 07m39s |   -0.53361 |             0.2571 |    0.0310 |      4.0126 |            81.3784 |      0.9965 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.6012024e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.13755466e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[249]\ttrain-mlogloss:0.317407+0.00205499\ttest-mlogloss:0.531648+0.00611509\n",
      "\n",
      "   12 | 10m08s |   -0.53165 |             0.6963 |    0.0857 |      7.7857 |             7.4061 |      0.9980 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[297]\ttrain-mlogloss:0.3626+0.00109793\ttest-mlogloss:0.530679+0.00569081\n",
      "\n",
      "   13 | 11m19s | \u001b[35m  -0.53068\u001b[0m | \u001b[32m            0.6965\u001b[0m | \u001b[32m   1.7892\u001b[0m | \u001b[32m     7.8753\u001b[0m | \u001b[32m           39.1605\u001b[0m | \u001b[32m     0.9618\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[318]\ttrain-mlogloss:0.392079+0.00131697\ttest-mlogloss:0.531813+0.00616492\n",
      "\n",
      "   14 | 11m36s |   -0.53181 |             0.6992 |    0.2915 |      7.8938 |            87.5962 |      0.9506 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[479]\ttrain-mlogloss:0.393693+0.0021383\ttest-mlogloss:0.531951+0.00605357\n",
      "\n",
      "   15 | 08m20s |   -0.53195 |             0.3057 |    1.8454 |      7.9363 |            99.9449 |      0.9729 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.61239547e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 66, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[306]\ttrain-mlogloss:0.306799+0.00222005\ttest-mlogloss:0.530631+0.00650793\n",
      "\n",
      "   16 | 09m52s | \u001b[35m  -0.53063\u001b[0m | \u001b[32m            0.5405\u001b[0m | \u001b[32m   1.9057\u001b[0m | \u001b[32m     7.9225\u001b[0m | \u001b[32m            0.2469\u001b[0m | \u001b[32m     0.9394\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[272]\ttrain-mlogloss:0.374891+0.00191893\ttest-mlogloss:0.531085+0.00536618\n",
      "\n",
      "   17 | 10m07s |   -0.53108 |             0.6754 |    0.0773 |      7.9590 |            47.4133 |      0.9948 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[400]\ttrain-mlogloss:0.335806+0.000635816\ttest-mlogloss:0.530281+0.00569156\n",
      "\n",
      "   18 | 05m54s | \u001b[35m  -0.53028\u001b[0m | \u001b[32m            0.2179\u001b[0m | \u001b[32m   1.9748\u001b[0m | \u001b[32m     7.2708\u001b[0m | \u001b[32m            8.3861\u001b[0m | \u001b[32m     0.9953\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.17918704e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[725]\ttrain-mlogloss:0.411064+0.00172843\ttest-mlogloss:0.533173+0.00570503\n",
      "\n",
      "   19 | 08m37s |   -0.53317 |             0.3743 |    0.0345 |      4.3025 |            39.7207 |      0.9970 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.48249339e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 59, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00055784]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[757]\ttrain-mlogloss:0.383803+0.00157551\ttest-mlogloss:0.531284+0.00544502\n",
      "\n",
      "   20 | 14m32s |   -0.53128 |             0.6942 |    1.9944 |      4.4958 |             5.2424 |      0.9152 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[295]\ttrain-mlogloss:0.359631+0.00222183\ttest-mlogloss:0.530929+0.00595874\n",
      "\n",
      "   21 | 09m59s |   -0.53093 |             0.6183 |    1.9930 |      7.9508 |            28.1155 |      0.9971 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([2.32287566e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[476]\ttrain-mlogloss:0.375193+0.000551209\ttest-mlogloss:0.535225+0.00610695\n",
      "\n",
      "   22 | 06m37s |   -0.53523 |             0.2225 |    0.4305 |      7.9226 |            77.7119 |      0.7058 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00016245]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 64, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[871]\ttrain-mlogloss:0.417301+0.00126282\ttest-mlogloss:0.53337+0.00595648\n",
      "\n",
      "   23 | 15m39s |   -0.53337 |             0.6550 |    1.2942 |      4.0978 |            99.9709 |      0.9784 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1014]\ttrain-mlogloss:0.431956+0.00367901\ttest-mlogloss:0.532465+0.00565556\n",
      "\n",
      "   24 | 18m26s |   -0.53247 |             0.6665 |    1.9084 |      4.1526 |            67.4150 |      0.9997 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00021514]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[426]\ttrain-mlogloss:0.381627+0.00219874\ttest-mlogloss:0.531337+0.00625846\n",
      "\n",
      "   25 | 14m58s |   -0.53134 |             0.6942 |    1.9010 |      7.5631 |            92.2117 |      0.9938 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[380]\ttrain-mlogloss:0.379907+0.00196816\ttest-mlogloss:0.530658+0.00540276\n",
      "\n",
      "   26 | 13m30s |   -0.53066 |             0.6796 |    1.9261 |      7.4059 |            73.1149 |      0.9947 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[237]\ttrain-mlogloss:0.332661+0.00198966\ttest-mlogloss:0.532112+0.00523573\n",
      "\n",
      "   27 | 09m34s |   -0.53211 |             0.6748 |    1.9573 |      7.9557 |             6.6300 |      0.7075 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00038862]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[411]\ttrain-mlogloss:0.376898+0.00111545\ttest-mlogloss:0.531383+0.00598973\n",
      "\n",
      "   28 | 12m45s |   -0.53138 |             0.6831 |    0.1204 |      6.4247 |            56.0197 |      0.9971 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[319]\ttrain-mlogloss:0.331205+0.0025693\ttest-mlogloss:0.530266+0.00614409\n",
      "\n",
      "   29 | 06m27s | \u001b[35m  -0.53027\u001b[0m | \u001b[32m            0.3013\u001b[0m | \u001b[32m   0.0072\u001b[0m | \u001b[32m     7.4086\u001b[0m | \u001b[32m           20.9770\u001b[0m | \u001b[32m     0.9886\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-5.83929941e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[297]\ttrain-mlogloss:0.385024+0.00227885\ttest-mlogloss:0.531139+0.00533732\n",
      "\n",
      "   30 | 11m03s |   -0.53114 |             0.6648 |    0.3351 |      7.8645 |            66.8106 |      0.9934 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00012488]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 62, 'nit': 8, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[382]\ttrain-mlogloss:0.386835+0.00153788\ttest-mlogloss:0.531992+0.00592885\n",
      "\n",
      "   31 | 13m44s |   -0.53199 |             0.6824 |    0.0176 |      7.6006 |            98.9509 |      0.9977 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00010357]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[360]\ttrain-mlogloss:0.366949+0.0015266\ttest-mlogloss:0.529938+0.0053791\n",
      "\n",
      "   32 | 12m19s | \u001b[35m  -0.52994\u001b[0m | \u001b[32m            0.6176\u001b[0m | \u001b[32m   1.9456\u001b[0m | \u001b[32m     7.6936\u001b[0m | \u001b[32m           51.3186\u001b[0m | \u001b[32m     0.9972\u001b[0m | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[746]\ttrain-mlogloss:0.402632+0.00173635\ttest-mlogloss:0.533307+0.00612593\n",
      "\n",
      "   33 | 06m38s |   -0.53331 |             0.2256 |    0.1606 |      4.8848 |            13.8207 |      0.9940 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00050872]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[805]\ttrain-mlogloss:0.393449+0.00178109\ttest-mlogloss:0.53184+0.00539254\n",
      "\n",
      "   34 | 11m33s |   -0.53184 |             0.5071 |    1.9999 |      4.7618 |             0.1091 |      0.9626 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[419]\ttrain-mlogloss:0.320418+0.00184309\ttest-mlogloss:0.53114+0.00598321\n",
      "\n",
      "   35 | 04m19s |   -0.53114 |             0.2031 |    1.8755 |      7.9402 |             3.5698 |      0.9687 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00039324]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[372]\ttrain-mlogloss:0.342411+0.00148167\ttest-mlogloss:0.531564+0.00581618\n",
      "\n",
      "   36 | 04m05s |   -0.53156 |             0.2305 |    0.1302 |      7.8416 |            34.0013 |      0.9881 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[584]\ttrain-mlogloss:0.398661+0.00179732\ttest-mlogloss:0.531492+0.00593788\n",
      "\n",
      "   37 | 04m36s |   -0.53149 |             0.2160 |    1.7859 |      5.8837 |            24.4480 |      0.9995 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-6.0223043e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[325]\ttrain-mlogloss:0.368698+0.00219931\ttest-mlogloss:0.530882+0.00555294\n",
      "\n",
      "   38 | 07m17s |   -0.53088 |             0.6792 |    0.0168 |      6.9453 |            25.5323 |      0.9705 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-4.37208801e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[371]\ttrain-mlogloss:0.386683+0.000985384\ttest-mlogloss:0.531046+0.0058204\n",
      "\n",
      "   39 | 07m02s |   -0.53105 |             0.6597 |    1.9690 |      6.0117 |            45.5006 |      0.9748 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[575]\ttrain-mlogloss:0.426814+0.00231161\ttest-mlogloss:0.533574+0.005126\n",
      "\n",
      "   40 | 07m56s |   -0.53357 |             0.6972 |    1.7498 |      4.0241 |            33.2748 |      0.9919 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-mlogloss:0.314608+0.00128621\ttest-mlogloss:0.532862+0.00630859\n",
      "\n",
      "   41 | 06m04s |   -0.53286 |             0.6554 |    0.0234 |      7.8037 |             0.0081 |      0.9455 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00040355]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00012308]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1093]\ttrain-mlogloss:0.405483+0.00219932\ttest-mlogloss:0.532698+0.0060757\n",
      "\n",
      "   42 | 07m00s |   -0.53270 |             0.2071 |    1.9605 |      5.6062 |            89.8575 |      0.9891 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00153965]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.76091669e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[529]\ttrain-mlogloss:0.363774+0.00110615\ttest-mlogloss:0.531196+0.00572672\n",
      "\n",
      "   43 | 05m00s |   -0.53120 |             0.2130 |    1.9776 |      7.9474 |            46.1771 |      0.9781 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00033648]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[377]\ttrain-mlogloss:0.364472+0.00130237\ttest-mlogloss:0.530664+0.00512062\n",
      "\n",
      "   44 | 08m57s |   -0.53066 |             0.6405 |    1.9702 |      7.9757 |            54.6617 |      0.9847 | \n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[417]\ttrain-mlogloss:0.381525+0.00210438\ttest-mlogloss:0.531444+0.00610889\n",
      "\n",
      "   45 | 10m07s |   -0.53144 |             0.6949 |    1.9897 |      7.4946 |            85.0715 |      0.9959 | \n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1))\n",
    "\n",
    "def xgb_evaluate(min_child_weight,\n",
    "                 colsample_bytree,\n",
    "                 max_depth,\n",
    "                 subsample,\n",
    "                 gamma):\n",
    "    params = dict()\n",
    "    params['objective'] = 'multi:softprob'\n",
    "    params['num_class'] = 3\n",
    "    params['eta'] = 0.1\n",
    "    params['max_depth'] = int(max_depth )   \n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['colsample_bytree'] = colsample_bytree\n",
    "    params['subsample'] = subsample\n",
    "    params['gamma'] = gamma\n",
    "    params['verbose_eval'] = True    \n",
    "\n",
    "\n",
    "    cv_result = xgb.cv(params, xgtrain,\n",
    "                       num_boost_round=100000,\n",
    "                       nfold=5,\n",
    "                       metrics={'mlogloss'},\n",
    "                       seed=1234,\n",
    "                       callbacks=[xgb.callback.early_stop(50)])\n",
    "\n",
    "    return -cv_result['test-mlogloss-mean'].min()\n",
    "\n",
    "\n",
    "xgb_BO = BayesianOptimization(xgb_evaluate, \n",
    "                             {'max_depth': (4, 8),\n",
    "                              'min_child_weight': (0, 100),\n",
    "                              'colsample_bytree': (0.2, 0.7),\n",
    "                              'subsample': (0.7, 1),\n",
    "                              'gamma': (0, 2)\n",
    "                             }\n",
    "                            )\n",
    "\n",
    "xgb_BO.maximize(init_points=5, n_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.617577</td>\n",
       "      <td>1.945618</td>\n",
       "      <td>7.693556</td>\n",
       "      <td>51.318581</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>-0.529938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.301330</td>\n",
       "      <td>0.007155</td>\n",
       "      <td>7.408636</td>\n",
       "      <td>20.976959</td>\n",
       "      <td>0.988617</td>\n",
       "      <td>-0.530266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.217855</td>\n",
       "      <td>1.974830</td>\n",
       "      <td>7.270835</td>\n",
       "      <td>8.386108</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>-0.530281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.540468</td>\n",
       "      <td>1.905727</td>\n",
       "      <td>7.922502</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.939417</td>\n",
       "      <td>-0.530631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.679584</td>\n",
       "      <td>1.926050</td>\n",
       "      <td>7.405918</td>\n",
       "      <td>73.114926</td>\n",
       "      <td>0.994703</td>\n",
       "      <td>-0.530658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree     gamma  max_depth  min_child_weight  subsample  \\\n",
       "26          0.617577  1.945618   7.693556         51.318581   0.997182   \n",
       "23          0.301330  0.007155   7.408636         20.976959   0.988617   \n",
       "12          0.217855  1.974830   7.270835          8.386108   0.995295   \n",
       "10          0.540468  1.905727   7.922502          0.246914   0.939417   \n",
       "20          0.679584  1.926050   7.405918         73.114926   0.994703   \n",
       "\n",
       "       score  \n",
       "26 -0.529938  \n",
       "23 -0.530266  \n",
       "12 -0.530281  \n",
       "10 -0.530631  \n",
       "20 -0.530658  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Show tuning results\n",
    "BO_scores = pd.DataFrame(xgb_BO.res['all']['params'])\n",
    "BO_scores['score'] = pd.DataFrame(xgb_BO.res['all']['values'])\n",
    "BO_scores = BO_scores.sort_values(by='score',ascending=False)\n",
    "BO_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train models\n",
    "\n",
    "Now we have optimized parameters, let's decrease the size of learning rate and train the model for better results.\n",
    "\n",
    "Firstly we'll use xgb.cv again to get optimal n_estimators, then we can use tuned n_esimator to finally train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 500 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1974]\ttrain-mlogloss:0.788571+0.00200216\ttest-mlogloss:0.788627+0.00801569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = dict()\n",
    "params['objective'] = 'multi:softprob'\n",
    "params['num_class'] = 3\n",
    "params['eta'] = 0.01\n",
    "params['max_depth'] = int(BO_scores.to_dict()['colsample_bytree'][0])\n",
    "params['min_child_weight'] = BO_scores.to_dict()['min_child_weight'][0]\n",
    "params['colsample_bytree'] = BO_scores.to_dict()['colsample_bytree'][0]\n",
    "params['subsample'] = BO_scores.to_dict()['subsample'][0]\n",
    "params['gamma'] = BO_scores.to_dict()['gamma'][0]\n",
    "params['seed']=1234\n",
    "\n",
    "cv_results = xgb.cv(params, xgb.DMatrix(train_x, label=train_y.reshape(train_x.shape[0],1)),\n",
    "               num_boost_round=1000000, nfold=5,\n",
    "       metrics={'mlogloss'},\n",
    "       seed=1234,\n",
    "       callbacks=[xgb.callback.early_stop(500)])\n",
    "\n",
    "best_iteration = len(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature_name  importance\n",
      "0                   hcc_manager_id_high    0.047156\n",
      "1                              latitude    0.045967\n",
      "2                             longitude    0.044390\n",
      "3                 hcc_manager_id_medium    0.043440\n",
      "4                     price_per_bedroom    0.042527\n",
      "5                        price_per_room    0.040639\n",
      "6                hcc_building_id_medium    0.038407\n",
      "7                                 price    0.038387\n",
      "8                  hcc_building_id_high    0.037708\n",
      "9           price_percentile_by_manager    0.036636\n",
      "10                      price_per_photo    0.033802\n",
      "11         price_percentile_by_building    0.033345\n",
      "12        price_percentile_by_disp_addr    0.032642\n",
      "13                         avg_word_len    0.030629\n",
      "14                           listing_id    0.028094\n",
      "15                   display_address_le    0.027944\n",
      "16                       building_id_le    0.027123\n",
      "17                    street_address_le    0.025959\n",
      "18                        manager_id_le    0.023327\n",
      "19                          len_of_desc    0.021540\n",
      "20                        words_of_desc    0.019992\n",
      "21                   price_per_bathroom    0.019652\n",
      "22               mean_price_by_building    0.017890\n",
      "23                         created_hour    0.017453\n",
      "24                mean_price_by_manager    0.016745\n",
      "25              median_price_by_manager    0.016652\n",
      "26                      num_of_features    0.016378\n",
      "27              mean_price_by_disp_addr    0.015969\n",
      "28             median_price_by_building    0.015128\n",
      "29            median_price_by_disp_addr    0.014514\n",
      "..                                  ...         ...\n",
      "88                        feature_sauna    0.000178\n",
      "89        feature_private_outdoor_space    0.000174\n",
      "90            feature_concierge_service    0.000162\n",
      "91                        feature_light    0.000154\n",
      "92                        created_month    0.000150\n",
      "93                   feature_s_kitchen_    0.000141\n",
      "94                          desc_street    0.000129\n",
      "95                         feature_pets    0.000081\n",
      "96                          desc_avenue    0.000069\n",
      "97                            desc_east    0.000061\n",
      "98              feature_newly_renovated    0.000057\n",
      "99                feature_outdoor_areas    0.000057\n",
      "100                 feature_unit_washer    0.000057\n",
      "101               feature_parking_space    0.000053\n",
      "102                         feature_gym    0.000040\n",
      "103                            desc_ave    0.000040\n",
      "104                feature_pets_allowed    0.000036\n",
      "105        feature_common_outdoor_space    0.000032\n",
      "106               feature_exposed_brick    0.000032\n",
      "107                feature_bike_storage    0.000028\n",
      "108             feature_shared_backyard    0.000024\n",
      "109                  feature_central_ac    0.000024\n",
      "110                        feature_flex    0.000016\n",
      "111          feature_childrens_playroom    0.000012\n",
      "112                   feature_mail_room    0.000012\n",
      "113          feature_short_term_allowed    0.000008\n",
      "114                   feature_central_a    0.000004\n",
      "115  feature_stainless_steel_appliances    0.000004\n",
      "116                   feature_courtyard    0.000004\n",
      "117                       feature_state    0.000004\n",
      "\n",
      "[118 rows x 2 columns]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/sub_xgb_tuned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c63860ff3342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msub_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"low\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"listing_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisting_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../output/sub_xgb_tuned.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1636\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1638\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/sub_xgb_tuned.csv'"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators = best_iteration,\n",
    "                              learning_rate=0.01,\n",
    "                              max_depth=int(BO_scores.to_dict()['max_depth'][0]),\n",
    "                              min_child_weight=BO_scores.to_dict()['min_child_weight'][0],\n",
    "                              colsample_bytree=BO_scores.to_dict()['colsample_bytree'][0],\n",
    "                              subsample=BO_scores.to_dict()['subsample'][0],\n",
    "                              gamma=BO_scores.to_dict()['gamma'][0],\n",
    "                              seed=1234,\n",
    "                              nthread=-1)\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "feature_importance = pd.DataFrame(sorted(zip(full_vars,clf.feature_importances_)\n",
    "                          , key=lambda x: x[1], reverse = True),columns=['feature_name','importance']) \n",
    "\n",
    "print (feature_importance.query('importance>0'))\n",
    "\n",
    "\n",
    "preds = clf.predict_proba(test_x)\n",
    "sub_df = pd.DataFrame(preds,columns = [\"low\", \"medium\", \"high\"])\n",
    "sub_df[\"listing_id\"] = test_data.listing_id.values\n",
    "sub_df.to_csv(\"../output/sub_xgb_tuned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"sub_xgb_tuned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
